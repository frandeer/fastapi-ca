"""
DI ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
ì„±ëŠ¥, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, í™•ì¥ì„± ë¶„ì„
"""

import time
import sys
import os
import tracemalloc
import gc
from typing import Protocol

# ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '../../examples/spring_di_demo'))

from spring_di import (
    service, repository, controller, component, autowired,
    ApplicationContext, Scope
)

# dependency-injectorì™€ ë¹„êµ
try:
    from dependency_injector import containers, providers
    from dependency_injector.wiring import inject, Provide
    HAS_DEPENDENCY_INJECTOR = True
except ImportError:
    HAS_DEPENDENCY_INJECTOR = False

# FastAPI ê¸°ë³¸ Dependsì™€ ë¹„êµ
from fastapi import Depends

class PerformanceBenchmark:

    def __init__(self):
        self.results = {}

    def measure_time_and_memory(self, func, *args, **kwargs):
        """ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •"""
        # ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
        tracemalloc.start()
        gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰

        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        end_time = time.perf_counter()

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()

        return {
            'result': result,
            'time': end_time - start_time,
            'memory_current': current / 1024 / 1024,  # MB
            'memory_peak': peak / 1024 / 1024,  # MB
        }

    def benchmark_spring_di_creation(self, iterations=1000):
        """Spring DI ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ëŠ¥"""

        # í…ŒìŠ¤íŠ¸ ì»´í¬ë„ŒíŠ¸ ì •ì˜
        @repository()
        class BenchmarkRepository:
            def get_data(self):
                return "data"

        @service()
        class BenchmarkService:
            def __init__(self, repo: BenchmarkRepository):
                self.repo = repo

            def process(self):
                return self.repo.get_data()

        def create_instances():
            instances = []
            for _ in range(iterations):
                service = ApplicationContext.get_bean(BenchmarkService)
                instances.append(service.process())
            return len(instances)

        result = self.measure_time_and_memory(create_instances)
        self.results['spring_di_creation'] = {
            'iterations': iterations,
            'time_per_iteration': result['time'] / iterations * 1000,  # ms
            'total_time': result['time'],
            'memory_current': result['memory_current'],
            'memory_peak': result['memory_peak']
        }

    def benchmark_dependency_injector(self, iterations=1000):
        """dependency-injectorì™€ ë¹„êµ"""
        if not HAS_DEPENDENCY_INJECTOR:
            self.results['dependency_injector'] = {'error': 'dependency-injector not installed'}
            return

        # dependency-injector ë²„ì „
        class Repository:
            def get_data(self):
                return "data"

        class Service:
            def __init__(self, repo: Repository):
                self.repo = repo

            def process(self):
                return self.repo.get_data()

        class Container(containers.DeclarativeContainer):
            repo = providers.Factory(Repository)
            service = providers.Factory(Service, repo=repo)

        container = Container()

        def create_instances():
            instances = []
            for _ in range(iterations):
                service = container.service()
                instances.append(service.process())
            return len(instances)

        result = self.measure_time_and_memory(create_instances)
        self.results['dependency_injector'] = {
            'iterations': iterations,
            'time_per_iteration': result['time'] / iterations * 1000,  # ms
            'total_time': result['time'],
            'memory_current': result['memory_current'],
            'memory_peak': result['memory_peak']
        }

    def benchmark_fastapi_depends(self, iterations=1000):
        """FastAPI ê¸°ë³¸ Dependsì™€ ë¹„êµ"""

        class Repository:
            def get_data(self):
                return "data"

        class Service:
            def __init__(self, repo: Repository):
                self.repo = repo

            def process(self):
                return self.repo.get_data()

        def get_repository():
            return Repository()

        def get_service(repo: Repository = Depends(get_repository)):
            return Service(repo)

        def create_instances():
            instances = []
            for _ in range(iterations):
                # FastAPI DependsëŠ” ì‹¤ì œë¡œëŠ” í”„ë ˆì„ì›Œí¬ê°€ í˜¸ì¶œí•˜ì§€ë§Œ
                # ì—¬ê¸°ì„œëŠ” ì§ì ‘ í˜¸ì¶œë¡œ ì‹œë®¬ë ˆì´ì…˜
                repo = get_repository()
                service = Service(repo)
                instances.append(service.process())
            return len(instances)

        result = self.measure_time_and_memory(create_instances)
        self.results['fastapi_depends'] = {
            'iterations': iterations,
            'time_per_iteration': result['time'] / iterations * 1000,  # ms
            'total_time': result['time'],
            'memory_current': result['memory_current'],
            'memory_peak': result['memory_peak']
        }

    def benchmark_manual_creation(self, iterations=1000):
        """ìˆ˜ë™ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ê³¼ ë¹„êµ (ë² ì´ìŠ¤ë¼ì¸)"""

        class Repository:
            def get_data(self):
                return "data"

        class Service:
            def __init__(self, repo: Repository):
                self.repo = repo

            def process(self):
                return self.repo.get_data()

        def create_instances():
            instances = []
            for _ in range(iterations):
                repo = Repository()
                service = Service(repo)
                instances.append(service.process())
            return len(instances)

        result = self.measure_time_and_memory(create_instances)
        self.results['manual_creation'] = {
            'iterations': iterations,
            'time_per_iteration': result['time'] / iterations * 1000,  # ms
            'total_time': result['time'],
            'memory_current': result['memory_current'],
            'memory_peak': result['memory_peak']
        }

    def benchmark_singleton_vs_prototype(self, iterations=1000):
        """ì‹±ê¸€í†¤ vs í”„ë¡œí† íƒ€ì… ìŠ¤ì½”í”„ ì„±ëŠ¥ ë¹„êµ"""

        @service(scope=Scope.SINGLETON)
        class SingletonService:
            def __init__(self):
                self.data = "singleton_data"

            def get_data(self):
                return self.data

        @service(scope=Scope.PROTOTYPE)
        class PrototypeService:
            def __init__(self):
                self.data = "prototype_data"

            def get_data(self):
                return self.data

        def test_singleton():
            results = []
            for _ in range(iterations):
                service = ApplicationContext.get_bean(SingletonService)
                results.append(service.get_data())
            return len(results)

        def test_prototype():
            results = []
            for _ in range(iterations):
                service = ApplicationContext.get_bean(PrototypeService)
                results.append(service.get_data())
            return len(results)

        singleton_result = self.measure_time_and_memory(test_singleton)
        prototype_result = self.measure_time_and_memory(test_prototype)

        self.results['singleton_scope'] = {
            'iterations': iterations,
            'time_per_iteration': singleton_result['time'] / iterations * 1000,
            'total_time': singleton_result['time'],
            'memory_current': singleton_result['memory_current'],
            'memory_peak': singleton_result['memory_peak']
        }

        self.results['prototype_scope'] = {
            'iterations': iterations,
            'time_per_iteration': prototype_result['time'] / iterations * 1000,
            'total_time': prototype_result['time'],
            'memory_current': prototype_result['memory_current'],
            'memory_peak': prototype_result['memory_peak']
        }

    def benchmark_deep_dependency_chain(self, iterations=100):
        """ê¹Šì€ ì˜ì¡´ì„± ì²´ì¸ ì„±ëŠ¥"""

        @repository()
        class Layer1:
            def get_data(self): return "layer1"

        @service()
        class Layer2:
            def __init__(self, layer1: Layer1): self.layer1 = layer1
            def get_data(self): return f"{self.layer1.get_data()}_layer2"

        @service()
        class Layer3:
            def __init__(self, layer2: Layer2): self.layer2 = layer2
            def get_data(self): return f"{self.layer2.get_data()}_layer3"

        @service()
        class Layer4:
            def __init__(self, layer3: Layer3): self.layer3 = layer3
            def get_data(self): return f"{self.layer3.get_data()}_layer4"

        @service()
        class Layer5:
            def __init__(self, layer4: Layer4): self.layer4 = layer4
            def get_data(self): return f"{self.layer4.get_data()}_layer5"

        def test_deep_chain():
            results = []
            for _ in range(iterations):
                service = ApplicationContext.get_bean(Layer5)
                results.append(service.get_data())
            return len(results)

        result = self.measure_time_and_memory(test_deep_chain)
        self.results['deep_dependency_chain'] = {
            'iterations': iterations,
            'time_per_iteration': result['time'] / iterations * 1000,
            'total_time': result['time'],
            'memory_current': result['memory_current'],
            'memory_peak': result['memory_peak']
        }

    def run_all_benchmarks(self):
        """ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("ğŸš€ DI ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")

        # ApplicationContext ì´ˆê¸°í™”
        ApplicationContext._components = {}
        ApplicationContext._component_configs = {}

        benchmarks = [
            ("Spring DI Creation", self.benchmark_spring_di_creation),
            ("Dependency Injector", self.benchmark_dependency_injector),
            ("FastAPI Depends", self.benchmark_fastapi_depends),
            ("Manual Creation", self.benchmark_manual_creation),
            ("Singleton vs Prototype", self.benchmark_singleton_vs_prototype),
            ("Deep Dependency Chain", self.benchmark_deep_dependency_chain),
        ]

        for name, benchmark in benchmarks:
            print(f"â±ï¸  {name} ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")
            try:
                benchmark()
                print(f"âœ… {name} ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ {name} ì‹¤íŒ¨: {e}")
                self.results[name.lower().replace(' ', '_')] = {'error': str(e)}

        return self.results

    def print_results(self):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š DI ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
        print("="*80)

        for name, result in self.results.items():
            if 'error' in result:
                print(f"\nâŒ {name.upper()}: {result['error']}")
                continue

            print(f"\nğŸ“ˆ {name.upper().replace('_', ' ')}")
            print(f"   ë°˜ë³µ íšŸìˆ˜: {result.get('iterations', 'N/A')}")
            print(f"   ë°˜ë³µë‹¹ ì‹œê°„: {result.get('time_per_iteration', 0):.4f} ms")
            print(f"   ì´ ì‹œê°„: {result.get('total_time', 0):.4f} s")
            print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {result.get('memory_current', 0):.2f} MB")
            print(f"   ìµœëŒ€ ë©”ëª¨ë¦¬: {result.get('memory_peak', 0):.2f} MB")

    def performance_comparison_table(self):
        """ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”"""
        print("\n" + "="*100)
        print("ğŸ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” (1000íšŒ ë°˜ë³µ ê¸°ì¤€)")
        print("="*100)
        print(f"{'ë°©ì‹':<25} {'ë°˜ë³µë‹¹ ì‹œê°„(ms)':<15} {'ì´ ì‹œê°„(s)':<12} {'ë©”ëª¨ë¦¬(MB)':<12} {'ìƒëŒ€ ì„±ëŠ¥':<10}")
        print("-" * 100)

        baseline_time = self.results.get('manual_creation', {}).get('time_per_iteration', 1)

        methods = [
            ('Manual Creation', 'manual_creation'),
            ('FastAPI Depends', 'fastapi_depends'),
            ('Spring DI', 'spring_di_creation'),
            ('Dependency Injector', 'dependency_injector'),
        ]

        for display_name, key in methods:
            if key in self.results and 'error' not in self.results[key]:
                result = self.results[key]
                time_per_iter = result.get('time_per_iteration', 0)
                total_time = result.get('total_time', 0)
                memory = result.get('memory_current', 0)
                relative_perf = f"{time_per_iter / baseline_time:.2f}x"

                print(f"{display_name:<25} {time_per_iter:<15.4f} {total_time:<12.4f} {memory:<12.2f} {relative_perf:<10}")

if __name__ == "__main__":
    benchmark = PerformanceBenchmark()
    results = benchmark.run_all_benchmarks()
    benchmark.print_results()
    benchmark.performance_comparison_table()